{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let's make some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 1.0\n",
    "while p>0.05:\n",
    "    a = np.random.normal(50.,7.4,size=100)\n",
    "    b = np.random.normal(53.5,15.9,size=200)\n",
    "    t,p = stats.ttest_ind(a,b,equal_var=False,)\n",
    "fig,ax = plt.subplots()\n",
    "ax.hist(a,color='blue',alpha=0.1)\n",
    "ax.hist(b,color='red',alpha=0.1)\n",
    "ax.axvspan(a.mean()-a.std()/np.sqrt(a.size),a.mean()+a.std()/np.sqrt(a.size),color='blue',alpha=0.7,label='sample a')\n",
    "ax.axvspan(b.mean()-b.std()/np.sqrt(b.size),b.mean()+b.std()/np.sqrt(b.size),color='red', alpha=0.7,label='sample b')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parametric independent t test with equal variance assumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(a,b,equal_var=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parametric independent t test without equal variance assumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(a,b,equal_var=False,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wilcoxon rank-sum statistics for two samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ranksums(a,b,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wilcoxon-Mann-Whitney statistics\n",
    "stats.mannwhitneyu(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nonparametric t test by permutation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "difference = np.mean(a) - np.mean(b)\n",
    "results=[]\n",
    "for ii in range(1000):\n",
    "    c = np.concatenate([a,b])\n",
    "    random.shuffle(c)\n",
    "    new_a = c[:100]\n",
    "    new_b = c[100:]\n",
    "    new_diff = new_a.mean() - new_b.mean()\n",
    "    results.append(new_diff)\n",
    "results = np.array(results)\n",
    "ax.hist(results,color='blue',alpha=0.6,bins=20)\n",
    "p = min([stats.percentileofscore(results,difference,)/100,1-stats.percentileofscore(results,difference,)/100])\n",
    "ax.axvline(difference,color='red',label='sample differences\\np value: %.2f'%p)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## redo the permutation test multiple times and sample the distribution of the p values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for ii in range(50):\n",
    "    temp=[]\n",
    "    for jj in range(1000):\n",
    "        c = np.concatenate([a,b])\n",
    "        random.shuffle(c)\n",
    "        new_a = c[:100]\n",
    "        new_b = c[100:]\n",
    "        new_diff = new_a.mean() - new_b.mean()\n",
    "        temp.append(new_diff)\n",
    "    temp = np.array(temp)\n",
    "    p=min([stats.percentileofscore(temp,difference,)/100,1-stats.percentileofscore(temp,difference,)/100])\n",
    "    results.append(p)\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(results,bins=10,label='p values: %.3f+/-%.3f'%(np.mean(results),np.std(results)))\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = np.concatenate([a,b])\n",
    "c_m = c.mean()\n",
    "c_s = c.std()*2\n",
    "with pm.Model() as model:\n",
    "    group1_mean = pm.Normal('group1_mean', c_m, sd=c_s)\n",
    "    group2_mean = pm.Normal('group2_mean', c_m, sd=c_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "σ_low = 6\n",
    "σ_high = 16\n",
    "\n",
    "with model:\n",
    "    group1_std = pm.Uniform('group1_std', lower=σ_low, upper=σ_high)\n",
    "    group2_std = pm.Uniform('group2_std', lower=σ_low, upper=σ_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with model:\n",
    "    v = pm.Exponential('v_minus_one',1/29.) +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with model:\n",
    "    λ1 = group1_std**-2\n",
    "    λ2 = group2_std**-2\n",
    "\n",
    "    group1 = pm.StudentT('drug', nu=v, mu=group1_mean, lam=λ1, \n",
    "                         observed=a)\n",
    "    group2 = pm.StudentT('placebo', nu=v, mu=group2_mean, lam=λ2, \n",
    "                         observed=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with model:\n",
    "    diff_of_means = pm.Deterministic('difference of means', \n",
    "                                     group1_mean - group2_mean)\n",
    "    diff_of_stds = pm.Deterministic('difference of stds', \n",
    "                                    group1_std - group2_std)\n",
    "    effect_size = pm.Deterministic('effect size',\n",
    "                                   diff_of_means / np.sqrt((group1_std**2 + group2_std**2) / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    trace = pm.sample(2000,init=None,njobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=pm.plot_posterior(trace[100:],\n",
    "                  varnames=['group1_mean', \n",
    "                            'group2_mean', \n",
    "                            'group1_std', \n",
    "                            'group2_std', \n",
    "                            'v_minus_one'],\n",
    "                  color='#87ceeb');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=pm.plot_posterior(trace[1000:],\n",
    "                  varnames=['difference of means', 'difference of stds', 'effect size'],\n",
    "                  ref_val=0,\n",
    "                  color='#87ceeb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=pm.forestplot(trace[1000:], \n",
    "                varnames=[v.name for v in model.vars[:2]],\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=pm.forestplot(trace[1000:], varnames=[v.name for v in model.vars[2:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# permutation test with classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold,permutation_test_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.concatenate([np.zeros(a.size),np.ones(b.size)])\n",
    "X = np.concatenate([a,b])\n",
    "#print(X.shape,label.shape)\n",
    "cv = StratifiedKFold(n_splits=5,shuffle=True,random_state=12345)\n",
    "clf = SVC(class_weight='balanced',random_state=12345)\n",
    "score, permutation_scores, sig = permutation_test_score(clf,X.reshape(-1,1),label,cv=cv,random_state=12345,n_permutations=300,\n",
    "                                                       scoring='roc_auc')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "ax.hist(permutation_scores,bins=50,label='randomized')\n",
    "ax.axvline(np.mean(permutation_scores),color='blue',lw=2,label='chance level')\n",
    "ax.axvline(score,color='red',lw=2,label='classification score')\n",
    "ax.legend()\n",
    "ax.set(title='support vector machine',xlabel='scoring metric',ylabel='Count')\n",
    "print('sig: %.4f'%sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# maybe we should try some other estimators to see whether we will have the same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['random forest','logistic regression', 'SVM linear kernel','KNN-default','extra tree','gaussian process']\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfs = [RandomForestClassifier(n_estimators=50,class_weight='balanced',random_state=12345),\n",
    "       LogisticRegression(class_weight='balanced',random_state=12345),\n",
    "       SVC(kernel='linear',class_weight='balanced',random_state=12345),\n",
    "       KNeighborsClassifier(),\n",
    "       ExtraTreeClassifier(class_weight='balanced',random_state=12345),\n",
    "       GaussianProcessClassifier(random_state=12345)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(16,8),nrows=2,ncols=3)\n",
    "for name,clf,ax in zip(names,clfs,axes.flatten()):\n",
    "    score, permutation_scores, sig = permutation_test_score(clf,X.reshape(-1,1),label,cv=cv,random_state=12345,n_permutations=300,\n",
    "                                                       scoring='roc_auc')\n",
    "    ax.hist(permutation_scores,bins=50,label='randomized')\n",
    "    ax.axvline(np.mean(permutation_scores),color='blue',lw=2,label='chance level:%.2f'%np.mean(permutation_scores))\n",
    "    ax.axvline(score,color='red',lw=2,label='clf.score:%.2f'%score)\n",
    "    ax.legend(loc='best')\n",
    "    ax.set(title=name)\n",
    "    print('finish %s,%.4f'%(name,sig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
